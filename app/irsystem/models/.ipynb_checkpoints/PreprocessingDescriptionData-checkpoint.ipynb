{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "from operator import itemgetter\n",
    "from nltk.stem import PorterStemmer\n",
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    clean = re.compile('<.*?>')\n",
    "    cleantext = re.sub(clean, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Returns a list of words that make up the text.    \n",
    "    Params: {text: String}\n",
    "    Returns: List\n",
    "    \"\"\"\n",
    "    return list(filter(str.strip, list(map(lambda x: x, re.findall(r'[a-zA-Z]*', text)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    stemmer=PorterStemmer()\n",
    "    stems = [stemmer.stem(w) for w in tokenize(text)]\n",
    "    return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = cleanhtml(text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    for (index,value) in data['Summary'].items():\n",
    "        value = preprocess_text(value)\n",
    "        value = stem(value)\n",
    "        data.loc[index,'Summary'] = value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feats = 5000\n",
    "doc_by_vocab = np.empty([len(data), n_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiezhao/venv/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1039: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "def build_vectorizer(max_features, stop_words, max_df=0.8, min_df=10, norm='l2'):\n",
    "    \"\"\"Returns a TfidfVectorizer object with the above preprocessing properties.\n",
    "    \n",
    "    Params: {max_features: Integer,\n",
    "             max_df: Float,\n",
    "             min_df: Float,\n",
    "             norm: String,\n",
    "             stop_words: String}\n",
    "    Returns: TfidfVectorizer\n",
    "    \"\"\"\n",
    "    \n",
    "    result = TfidfVectorizer(max_features = max_features, stop_words = stop_words, max_df = max_df, min_df = min_df, norm = norm)\n",
    "    return result\n",
    "\n",
    "data = preprocess(data)\n",
    "tfidf_vec = build_vectorizer(n_feats, \"english\")\n",
    "doc_by_vocab = tfidf_vec.fit_transform([value for _,value in data['Summary'].items()]).toarray()\n",
    "index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}\n",
    "movie_index_to_name = data['Title'].to_dict()\n",
    "movie_name_to_index = {v: k for k, v in movie_index_to_name.items()}\n",
    "num_movies = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim(mov1, mov2, input_doc_mat, movie_name_to_index):\n",
    "    \"\"\"Returns a float giving the cosine similarity of \n",
    "       the two movie transcripts.\n",
    "    \n",
    "    Params: {mov1: String,\n",
    "             mov2: String,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_name_to_index: Dict}\n",
    "    Returns: Float (Cosine similarity of the two movie transcripts.)\n",
    "    \"\"\"\n",
    "    idx1 = movie_name_to_index[mov1]\n",
    "    idx2 = movie_name_to_index[mov2]\n",
    "    movie1 = input_doc_mat[idx1,]\n",
    "    movie2 = input_doc_mat[idx2,]\n",
    "    dot_product = np.dot(movie1, movie2)\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiezhao/venv/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1039: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "def build_movie_sims_cos(n_mov, movie_index_to_name, input_doc_mat, movie_name_to_index, input_get_sim_method):\n",
    "    \"\"\"Returns a movie_sims matrix of size (num_movies,num_movies) where for (i,j):\n",
    "        [i,j] should be the cosine similarity between the movie with index i and the movie with index j\n",
    "    \n",
    "    Params: {n_mov: Integer,\n",
    "             movie_index_to_name: Dict,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_name_to_index: Dict,\n",
    "             input_get_sim_method: Function}\n",
    "    Returns: Numpy Array\n",
    "    \"\"\"\n",
    "    result = np.zeros((n_mov, n_mov))\n",
    "    for i in range(n_mov):\n",
    "        for j in range(n_mov):\n",
    "            if i == j:\n",
    "                result[i,j] = 0\n",
    "            else:\n",
    "                mov1 = movie_index_to_name[i]\n",
    "                mov2 = movie_index_to_name[j]\n",
    "                result[i,j] = input_get_sim_method(mov1, mov2, input_doc_mat, movie_name_to_index)\n",
    "    \n",
    "            \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Drama_Title  Summary_Similarity  Genre_Similarity  \\\n",
      "667                     Stranger            0.432997               1.0   \n",
      "415          Sweet Savage Family            0.276500               1.0   \n",
      "722          The Queen of Office            0.237680               1.0   \n",
      "824           The Wedding Scheme            0.218926               1.0   \n",
      "242        Bad Thief, Good Thief            0.212300               1.0   \n",
      "312                  Be Positive            0.212232               1.0   \n",
      "428             You Will Love Me            0.210892               1.0   \n",
      "498                    The Lover            0.208423               1.0   \n",
      "333  Cinderella and Four Knights            0.207837               1.0   \n",
      "32              The Best Chicken            0.205444               1.0   \n",
      "\n",
      "     Network_Similarity     Total  \n",
      "667                   0  1.432997  \n",
      "415                   0  1.276500  \n",
      "722                   0  1.237680  \n",
      "824                   0  1.218926  \n",
      "242                   0  1.212300  \n",
      "312                   0  1.212232  \n",
      "428                   0  1.210892  \n",
      "498                   0  1.208423  \n",
      "333                   0  1.207837  \n",
      "32                    0  1.205444  \n"
     ]
    }
   ],
   "source": [
    "movie_sims_cos = build_movie_sims_cos(num_movies, movie_index_to_name, doc_by_vocab, movie_name_to_index, get_sim)\n",
    "print(movie_sims_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comedy'}\n",
      "Doctor Stranger\n",
      "Doctors\n",
      "Black [ 0.01709852  0.04143856  0.0366299  ...,  0.08625637  0.02484349  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drama_Title</th>\n",
       "      <th>Summary_Similarity</th>\n",
       "      <th>Genre_Similarity</th>\n",
       "      <th>Network_Similarity</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Eulachacha Waikiki</td>\n",
       "      <td>0.207334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.207334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>Cute or Crazy</td>\n",
       "      <td>0.194104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.194104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Little Girl Detective</td>\n",
       "      <td>0.187680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.187680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eulachacha Waikiki (Season 2)</td>\n",
       "      <td>0.181441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.181441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Rude Miss Young Ae (Season 10)</td>\n",
       "      <td>0.172290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Rude Miss Young Ae (Season 9)</td>\n",
       "      <td>0.161642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.161642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Kid Gang</td>\n",
       "      <td>0.127783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.127783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Rude Miss Young Ae (Season 14)</td>\n",
       "      <td>0.127070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.127070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Rude Miss Young Ae (Season 11)</td>\n",
       "      <td>0.122168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.122168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Rude Miss Young Ae (Season 12)</td>\n",
       "      <td>0.119842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.119842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Drama_Title  Summary_Similarity  Genre_Similarity  \\\n",
       "149               Eulachacha Waikiki            0.207334               1.0   \n",
       "1324                   Cute or Crazy            0.194104               1.0   \n",
       "845            Little Girl Detective            0.187680               1.0   \n",
       "6      Eulachacha Waikiki (Season 2)            0.181441               1.0   \n",
       "820   Rude Miss Young Ae (Season 10)            0.172290               1.0   \n",
       "903    Rude Miss Young Ae (Season 9)            0.161642               1.0   \n",
       "1220                        Kid Gang            0.127783               1.0   \n",
       "456   Rude Miss Young Ae (Season 14)            0.127070               1.0   \n",
       "752   Rude Miss Young Ae (Season 11)            0.122168               1.0   \n",
       "687   Rude Miss Young Ae (Season 12)            0.119842               1.0   \n",
       "\n",
       "      Network_Similarity     Total  \n",
       "149                    0  1.207334  \n",
       "1324                   0  1.194104  \n",
       "845                    0  1.187680  \n",
       "6                      0  1.181441  \n",
       "820                    0  1.172290  \n",
       "903                    0  1.161642  \n",
       "1220                   0  1.127783  \n",
       "456                    0  1.127070  \n",
       "752                    0  1.122168  \n",
       "687                    0  1.119842  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_match(n_mov, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, dramas_enjoyed, dramas_disliked, preferred_genres, preferred_network, num_results):\n",
    "    feature_list = ['Summary_Similarity', 'Genre_Similarity', 'Network_Similarity', 'Total']\n",
    "    result = pd.DataFrame(0, index=np.arange(n_mov), columns=feature_list)\n",
    "    genres = set()\n",
    "    preferred_genres = [preprocess_text(value) for value in preferred_genres]\n",
    "    genres.update(preferred_genres)\n",
    "    print(genres)\n",
    "    for drama in dramas_enjoyed:\n",
    "        print(drama)\n",
    "        if drama in movie_name_to_index.keys():\n",
    "            index = movie_name_to_index[drama]\n",
    "            sim = movie_sims_cos[index,:]\n",
    "            result['Summary_Similarity']+= pd.Series(sim)\n",
    "            \n",
    "    for drama in dramas_disliked:\n",
    "        if drama in movie_name_to_index.keys():\n",
    "            index = movie_name_to_index[drama]\n",
    "            sim = movie_sims_cos[index,:]\n",
    "            result['Summary_Similarity']-= pd.Series(sim)\n",
    "            print(drama, sim)\n",
    "            \n",
    "    for index, value in data.iterrows():\n",
    "        gen = str(value['Genre'])\n",
    "        gen = preprocess_text(gen)\n",
    "        drama_genres = set()\n",
    "        drama_genres.update(gen.split())\n",
    "        result.loc[index,'Genre_Similarity'] = len(genres.intersection(drama_genres))/len(genres.union(drama_genres))\n",
    "        if preferred_network == data.iloc[index]['Network']:\n",
    "            result['Network_Similarity']+=1\n",
    "    result['Total'] = result.sum(axis = 1)\n",
    "    result = result.sort_values(by='Total', ascending=False)\n",
    "    result = result[:num_results]\n",
    "    indices =  result.index.tolist()\n",
    "    best_dramas = pd.Series([movie_index_to_name[index] for index in indices],index = result.index)\n",
    "    result.insert(loc=0, column='Drama_Title', value=best_dramas)\n",
    "    result.reset_index()\n",
    "    return result\n",
    "\n",
    "best_match(num_movies, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, [\"Doctor Stranger\",\"Doctors\"], ['Black'], [\"comedy\"], [], 10)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display (n_mov, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, dramas_enjoyed, dramas_disliked, preferred_genres, preferred_network, num_results):\n",
    "    dramas_enjoyed = dramas_enjoyed.split(', ')\n",
    "    print(dramas_enjoyed)\n",
    "    dramas_disliked = dramas_disliked.split(', ')\n",
    "    preferred_genres = preferred_genres.split(', ')\n",
    "    preferred_network = preferred_network.split(', ')\n",
    "    best = best_match(n_mov, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, dramas_enjoyed, dramas_disliked, preferred_genres, preferred_network, num_results)\n",
    "    title = list(zip(best['Drama_Title'], best[\"Total\"]))\n",
    "    final = [\"Drama Titles: {}\".format(final_title[0]) + \"            \" +\"Total Similarity {}\".format(final_title[1]) for final_title in title]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Doctor Stranger', 'Doctors']\n",
      "{'comedy'}\n",
      "Doctor Stranger\n",
      "Doctors\n",
      "Black [ 0.01709852  0.04143856  0.0366299  ...,  0.08625637  0.02484349  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Drama Titles: Eulachacha Waikiki            Total Similarity 1.2073338192508194',\n",
       " 'Drama Titles: Cute or Crazy            Total Similarity 1.1941036047353362',\n",
       " 'Drama Titles: Little Girl Detective            Total Similarity 1.1876804160218053',\n",
       " 'Drama Titles: Eulachacha Waikiki (Season 2)            Total Similarity 1.181441135978635',\n",
       " 'Drama Titles: Rude Miss Young Ae (Season 10)            Total Similarity 1.1722903328555556',\n",
       " 'Drama Titles: Rude Miss Young Ae (Season 9)            Total Similarity 1.1616415100913604',\n",
       " 'Drama Titles: Kid Gang            Total Similarity 1.1277834518971648',\n",
       " 'Drama Titles: Rude Miss Young Ae (Season 14)            Total Similarity 1.1270701761623845',\n",
       " 'Drama Titles: Rude Miss Young Ae (Season 11)            Total Similarity 1.122167589310805',\n",
       " 'Drama Titles: Rude Miss Young Ae (Season 12)            Total Similarity 1.1198419101576236']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(num_movies, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, \"Doctor Stranger, Doctors\", 'Black', \"comedy\", '', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
